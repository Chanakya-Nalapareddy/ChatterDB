# ChatterDB
ChatterDB â€” From data to dialogue. A metadata-driven system for querying databases using natural language.

# ğŸ“Š ChatterDB â€“ Metadata Catalog, Analytics & NLQ Platform : From data to dialogue. A metadata-driven system for querying databases using natural language.

ChatterDB is an **end-to-end, metadata-driven data exploration and analytics platform** that combines:

- **Metadata cataloging**
- **Interactive Power BI dashboards**
- **Retrieval-Augmented Generation (RAG)**
- **Natural Language â†’ SQL â†’ Results â†’ Natural Language**
- **Automatic plots and visualizations**

The goal of this project is to make **databases explorable and queryable using natural language**, while remaining **transparent, safe, auditable, and developer-friendly**.

This README intentionally contains **both functional and deep technical explanations** so the project can be understood by:
- Data engineers
- Analytics engineers
- ML / LLM engineers
- BI developers
- Reviewers and interviewers

---

## ğŸ§  Problem Statement

Modern data platforms suffer from:
- Poor schema discoverability
- Tribal knowledge of tables and joins
- SQL complexity for non-technical users
- LLM hallucinations when querying databases
- Lack of trust and auditability in NLQ systems

**ChatterDB solves this by grounding LLMs in metadata, semantics, and validation.**

---

## ğŸ— High-Level Architecture

```
User
 â†“ Natural Language Question
Streamlit UI
 â†“
Conversation Context (SQLite)
 â†“
Semantic + Metadata Retrieval (RAG)
 â†“
LLM (Intent + SQL Generation)
 â†“
SQL Intent Validation
 â†“
DuckDB Execution Engine
 â†“
Result DataFrame
 â†“
Auto Chart Selection
 â†“
LLM (Result â†’ Natural Language Explanation)
 â†“
Answer + Charts + SQL
```

---

## ğŸš€ Core Components (Detailed)

---

## 1ï¸âƒ£ Metadata Foundation (Data Catalog)

The system begins by extracting **database metadata** directly from DuckDB using `information_schema`.

### MetaDataMaster Table
One row per column, containing:

- database_name
- table_schema
- table_name
- table_type
- ordinal_position
- column_name
- data_type
- max_length_bytes
- precision
- scale
- is_nullable
- obj_order

This table is **authoritative** and used everywhere:
- Power BI dashboards
- Semantic layer grounding
- RAG retrieval
- SQL validation

> This ensures the LLM never operates blindly.

---

## 2ï¸âƒ£ Power BI â€“ Visual Metadata Explorer

Power BI provides a **human-first schema discovery layer**.

### Capabilities
- Filter by database / schema / table
- Keyword search across all metadata fields
- Drill-down from schema â†’ table â†’ column
- Acts as a visual data dictionary

Power BI is **not optional UI fluff** â€” it directly improves NLQ accuracy by helping users ask better questions.

---

## 3ï¸âƒ£ Semantic Layer (YAML)

Instead of letting the LLM infer meaning from raw schemas, the project introduces a **semantic abstraction layer** defined in YAML.

### What the Semantic Layer Does
- Maps business concepts â†’ physical tables
- Defines metrics, dimensions, and relationships
- Restricts which columns are allowed in queries
- Provides business-friendly naming

Example (conceptual):
```yaml
entities:
  sales:
    table: fact_sales
    measures:
      - total_revenue
      - total_orders
    dimensions:
      - country
      - order_date
```

This is the **first safety barrier**.

---

## 4ï¸âƒ£ Retrieval-Augmented Generation (RAG) â€“ Technical Details

ChatterDB uses **RAG to ground LLM behavior**.

### What Is Retrieved
- Relevant tables from MetaDataMaster
- Column descriptions and data types
- Semantic layer definitions
- Prior conversation turns

### Retrieval Sources
- **Vector database (LanceDB)** for embeddings
- **Structured metadata tables**
- **Conversation history (SQLite)**

### Why RAG Is Critical
Without RAG:
- LLM guesses schema
- Hallucinates joins
- Generates invalid SQL

With RAG:
- LLM sees only relevant schema slices
- Context window stays small
- Accuracy improves dramatically

> RAG is used for **context injection**, not answer generation.

---

## 5ï¸âƒ£ Vector Database (LanceDB)

LanceDB is used as the **vector store** for:
- Table names
- Column names
- Semantic descriptions
- Example queries

### Embedding Strategy
- Text chunks are embedded using OpenAI embeddings
- Stored locally in `.lancedb/`
- Queried using semantic similarity at runtime

This allows questions like:
> â€œcustomer revenue by regionâ€

to retrieve:
- `customers.country`
- `sales.revenue`
- `orders.customer_id`

even if those words donâ€™t exactly match.

---

## 6ï¸âƒ£ Natural Language â†’ SQL Generation

### Process
1. User asks a question
2. Relevant metadata is retrieved (RAG)
3. Semantic layer constraints are applied
4. LLM generates SQL
5. SQL is checked for:
   - Table validity
   - Column validity
   - Aggregation correctness
   - Intent alignment

### SQL Validation
A custom **SQL intent validator** ensures:
- No hallucinated columns
- No invalid aggregations
- No schema violations

Invalid SQL is rejected and regenerated.

---

## 7ï¸âƒ£ DuckDB Execution Engine

Once validated:
- SQL runs directly on DuckDB
- Results are returned as Pandas DataFrames
- Supports joins, aggregations, filters, windows

DuckDB is chosen because it is:
- Fast
- Embedded
- SQL-compliant
- Analytics-optimized

---

## 8ï¸âƒ£ Automatic Charts & Visualizations

Based on result shape:
- Time-based â†’ line charts
- Categorical aggregates â†’ bar charts
- Distributions â†’ histograms
- Small results â†’ tables

Charts are rendered using:
- Matplotlib (backend)
- Streamlit (frontend)

This is **data-driven visualization**, not hardcoded charts.

---

## 9ï¸âƒ£ Results â†’ Natural Language Explanation

After execution:
- Results summary is passed back to the LLM
- The LLM explains:
  - Trends
  - Outliers
  - Comparisons

Example:
> â€œRevenue peaked in Q3, driven primarily by the US market.â€

This completes the **NL â†’ SQL â†’ NL loop**.

---

## ğŸ” Conversation Memory

- Chat history stored in SQLite
- Enables follow-up questions
- Maintains conversational context
- Thread-based conversations

Example:
> â€œWhat about only last quarter?â€

---

## ğŸ—‚ Project Structure

```
chatterdb/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ rag_semantic/
â”‚       â”œâ”€â”€ rag_app.py
â”‚       â”œâ”€â”€ sql_generator_gpt.py
â”‚       â”œâ”€â”€ semantic_model.py
â”‚       â”œâ”€â”€ sql_intent_validator.py
â”‚       â””â”€â”€ thread_store_sqlite.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ warehouse/
â”‚   â”‚   â””â”€â”€ chatterdb.duckdb
â”‚   â””â”€â”€ chat_threads.sqlite
â”‚
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ Metadata_Catalog.pbix
â”‚   â””â”€â”€ MetaDataMaster.csv
â”‚
â”œâ”€â”€ streamlit_rag_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ›  Running the Project

```bash
pip install -r requirements.txt
cp .env.example .env
streamlit run streamlit_rag_app.py
```

---

## ğŸ§ª Typical User Flow

1. Explore schema in Power BI
2. Discover relevant tables/columns
3. Ask a natural language question
4. Review generated SQL (optional)
5. View charts + explanation
6. Ask follow-up questions

---

## ğŸ“Œ Design Principles

- Metadata-first
- Semantic grounding
- Retrieval before generation
- Validation before execution
- Explainability by default

---

## ğŸ“œ License

MIT License

---

## ğŸ™Œ Acknowledgements

DuckDB â€¢ Streamlit â€¢ Power BI â€¢ LanceDB â€¢ LangChain â€¢ Azure OpenAI
